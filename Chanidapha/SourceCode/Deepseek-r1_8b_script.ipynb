{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqGyuZITXW457d0nXekOUy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TS1_TSl5u_-_"},"outputs":[],"source":["# @title 0. Mount Google Drive\n","from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","\n","print(\"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!\")"]},{"cell_type":"code","source":["# @title 1. Setup Environment & Install DeepSeek-R1\n","\n","!curl -fsSL https://ollama.com/install.sh | sh\n","!pip install pandas tqdm\n","\n","import subprocess\n","import time\n","import os\n","\n","# Start Ollama Server\n","print(\"Starting Ollama Server...\")\n","process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","time.sleep(5)\n","\n","MODEL_NAME = \"deepseek-r1:latest\"\n","print(f\"Downloading model: {MODEL_NAME}...\")\n","!ollama pull {MODEL_NAME}\n","\n","print(\"‚úÖ Setup Complete!\")"],"metadata":{"id":"Oq3SRuz14fBM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 2. Configuration\n","import pandas as pd\n","import requests\n","import json\n","import os\n","import re\n","from tqdm import tqdm\n","\n","TARGET_FILE_NAME = \"sentiment_ner.csv\"\n","\n","INPUT_DIR = \"/content/drive/MyDrive/ReaLearn/FY 2025/Interns - NU, Batch 3/AJCC_2026/Chanidapha/Dataset\"\n","OUTPUT_DIR = \"/content/drive/MyDrive/ReaLearn/FY 2025/Interns - NU, Batch 3/AJCC_2026/Chanidapha/Result/Deepseek-r1_temp1_Topp0.07/sentiment_ner\"\n","INPUT_COLUMN = \"Perturbed\"\n","TARGET_MODEL = \"deepseek-r1:latest\"\n","OUTPUT_FILENAME_PREFIX = \"Result_Deepseek-r1_temp1_\"\n","\n","print(f\"‚úÖ Config Saved: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå {TARGET_FILE_NAME} ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• {TARGET_MODEL}\")"],"metadata":{"id":"i39D7zkn4ge_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 3. Helper Functions\n","\n","def clean_deepseek_response(text):\n","    if not text: return \"Error\"\n","\n","    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n","\n","    text_lower = text.lower()\n","    if \"positive\" in text_lower: return \"Positive\"\n","    elif \"negative\" in text_lower: return \"Negative\"\n","    elif \"neutral\" in text_lower: return \"Neutral\"\n","    else: return text.strip()\n","\n","def create_prompt(sentence):\n","    system_part = \"\"\"You are an assistant that classifies the sentiment of the\n","message into positive, negative, and neutral. Given below is an example\n","of the sentiment analysis task.\n","\n","Sentence: I had a bad experience\n","Sentiment: Negative\"\"\"\n","\n","    user_part = f\"\"\"What is the sentiment of the following sentence? Limit your\n","answer to only one of these options: Positive, Negative, or Neutral.\n","{sentence}\"\"\"\n","\n","    return [\n","        {\"role\": \"system\", \"content\": system_part},\n","        {\"role\": \"user\", \"content\": user_part}\n","    ]\n","\n","def query_ollama(model, messages):\n","    url = \"http://localhost:11434/api/chat\"\n","    payload = {\n","        \"model\": model, \"messages\": messages, \"stream\": False,\n","        \"options\": {\"temperature\": 1.0,\n","                    \"top_p\": 0.07}\n","    }\n","    try:\n","        response = requests.post(url, json=payload)\n","        if response.status_code == 200:\n","            return response.json()['message']['content']\n","        else:\n","            return f\"Error: {response.status_code}\"\n","    except Exception as e:\n","        return f\"Error: {e}\"\n","\n","print(\"‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\")"],"metadata":{"id":"qzvpUH014xMz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title 4. Start Processing\n","NUM_RUNS = 3\n","\n","input_path = os.path.join(INPUT_DIR, TARGET_FILE_NAME)\n","target_output_filename = f\"{OUTPUT_FILENAME_PREFIX}{TARGET_FILE_NAME}\"\n","output_path = os.path.join(OUTPUT_DIR, f\"{OUTPUT_FILENAME_PREFIX}{TARGET_FILE_NAME}\")\n","\n","print(f\"üöÄ Processing: {TARGET_FILE_NAME}\")\n","print(f\"üîÑ Mode: Multiple Runs ({NUM_RUNS} times per sentence)\")\n","print(f\"üìÇ Reading from: {input_path}\")\n","\n","if not os.path.exists(input_path):\n","    print(f\"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå '{input_path}'\")\n","else:\n","    try:\n","        df = pd.read_csv(input_path)\n","        if INPUT_COLUMN not in df.columns:\n","            print(f\"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠ '{INPUT_COLUMN}' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV\")\n","        else:\n","            all_predictions = {f\"Prediction{i}\": [] for i in range(1, NUM_RUNS + 1)}\n","\n","            # --- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏ô‡∏•‡∏π‡∏õ ---\n","            for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Generating\"):\n","                sentence = str(row[INPUT_COLUMN])\n","                prompt_messages = create_prompt(sentence)\n","                for i in range(1, NUM_RUNS + 1):\n","                    raw_res = query_ollama(TARGET_MODEL, prompt_messages)\n","                    final_pred = clean_deepseek_response(raw_res)\n","\n","                    # ‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏á list ‡∏Ç‡∏≠‡∏á‡∏£‡∏≠‡∏ö‡∏ô‡∏±‡πâ‡∏ô‡πÜ\n","                    all_predictions[f\"Prediction{i}\"].append(final_pred)\n","\n","            ref_col_name = 'Expected_answer'\n","\n","            if ref_col_name in df.columns:\n","                insert_loc_start = df.columns.get_loc(ref_col_name) + 1\n","            else:\n","                print(f\"‚ö†Ô∏è Warning: ‡πÑ‡∏°‡πà‡∏û‡∏ö '{ref_col_name}'.. ‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î\")\n","                insert_loc_start = len(df.columns)\n","\n","            # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏≠‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏™‡πà‡∏ï‡∏≤‡∏£‡∏≤‡∏á\n","            for i in range(1, NUM_RUNS + 1):\n","                col_name = f\"Prediction{i}\"\n","\n","                if col_name in df.columns:\n","                    df.drop(columns=[col_name], inplace=True)\n","\n","                current_insert_loc = insert_loc_start + (i - 1)\n","\n","                if ref_col_name not in df.columns:\n","                    df[col_name] = all_predictions[col_name]\n","                else:\n","                    # ‡πÅ‡∏ó‡∏£‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n","                    if current_insert_loc > len(df.columns):\n","                        df[col_name] = all_predictions[col_name]\n","                    else:\n","                        df.insert(current_insert_loc, col_name, all_predictions[col_name])\n","\n","            # --- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå ---\n","            os.makedirs(OUTPUT_DIR, exist_ok=True)\n","            df.to_csv(output_path, index=False)\n","            print(f\"\\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ 3 Predictions ‡∏ó‡∏µ‡πà: {output_path}\")\n","\n","    except Exception as e:\n","        print(f\"\\n‚ùå Critical Error: {e}\")"],"metadata":{"id":"kKfA2Wvg4zrg"},"execution_count":null,"outputs":[]}]}