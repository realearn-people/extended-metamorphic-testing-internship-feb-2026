{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 13450,
     "status": "ok",
     "timestamp": 1766559557292,
     "user": {
      "displayName": "teeradaj racharak",
      "userId": "17075908059307261120"
     },
     "user_tz": -540
    },
    "id": "cadfC0lSfwfQ",
    "outputId": "3926f2e7-7415-40a5-d78e-c95c6c9f7acd"
   },
   "outputs": [],
   "source": [
    "# @title 0. Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 79284,
     "status": "ok",
     "timestamp": 1766559636578,
     "user": {
      "displayName": "teeradaj racharak",
      "userId": "17075908059307261120"
     },
     "user_tz": -540
    },
    "id": "CYz_HOmtf9LG",
    "outputId": "bb313f92-7c97-40b4-9ae9-b91f48956fa8"
   },
   "outputs": [],
   "source": [
    "# @title 1. Setup Environment & Install\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "!pip install pandas tqdm\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"Starting Ollama Server...\")\n",
    "process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "time.sleep(5)\n",
    "\n",
    "MODEL_NAME = \"gemma3:1b\"\n",
    "print(f\"Downloading model: {MODEL_NAME}...\")\n",
    "!ollama pull {MODEL_NAME}\n",
    "\n",
    "print(f\"‚úÖ Setup Complete! Model {MODEL_NAME} is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1766559637265,
     "user": {
      "displayName": "teeradaj racharak",
      "userId": "17075908059307261120"
     },
     "user_tz": -540
    },
    "id": "JtjY-IM5gLOC",
    "outputId": "9d2ff34b-b9e3-40c8-efa1-1a7341ec7801"
   },
   "outputs": [],
   "source": [
    "# @title 2. Configuration\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "TARGET_FILE_NAME = \"sentiment_temporal.csv\"\n",
    "\n",
    "INPUT_DIR = \"/content/drive/MyDrive/ReaLearn/FY 2025/Interns - NU, Batch 3/AJCC_2026/Chanidapha/Dataset\"\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/ReaLearn/FY 2025/Interns - NU, Batch 3/AJCC_2026/Chanidapha/Result/gemma3:1b_temp1_Topp0.07/sentiment_temporal\"\n",
    "INPUT_COLUMN = \"Perturbed\"\n",
    "TARGET_MODEL = \"gemma3:1b\"\n",
    "OUTPUT_FILENAME_PREFIX = \"Result_gemma3:1b_temp1_\"\n",
    "\n",
    "print(f\"‚úÖ Config Saved: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå {TARGET_FILE_NAME} ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• {TARGET_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1766559637292,
     "user": {
      "displayName": "teeradaj racharak",
      "userId": "17075908059307261120"
     },
     "user_tz": -540
    },
    "id": "PS-wLNoWgbu-",
    "outputId": "e78715cc-9e90-49c0-c677-e2a827f565a8"
   },
   "outputs": [],
   "source": [
    "# @title 3. Helper Functions\n",
    "\n",
    "def clean_gemma_response(text):\n",
    "\n",
    "    if not text: return \"Error\"\n",
    "\n",
    "    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    if \"positive\" in text_lower: return \"Positive\"\n",
    "    elif \"negative\" in text_lower: return \"Negative\"\n",
    "    elif \"neutral\" in text_lower: return \"Neutral\"\n",
    "    else: return text.strip()\n",
    "\n",
    "def create_prompt(sentence):\n",
    "    system_part = \"\"\"You are an assistant that classifies the sentiment of the\n",
    "message into positive, negative, and neutral. Given below is an example\n",
    "of the sentiment analysis task.\n",
    "\n",
    "Sentence: I had a bad experience\n",
    "Sentiment: Negative\"\"\"\n",
    "\n",
    "    user_part = f\"\"\"What is the sentiment of the following sentence? Limit your\n",
    "answer to only one of these options: Positive, Negative, or Neutral.\n",
    "{sentence}\"\"\"\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_part},\n",
    "        {\"role\": \"user\", \"content\": user_part}\n",
    "    ]\n",
    "\n",
    "def query_ollama(model, messages):\n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 1.0,\n",
    "                    \"top_p\": 0.07}\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['message']['content']\n",
    "        else:\n",
    "            return f\"Error: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "print(\"‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218568,
     "status": "ok",
     "timestamp": 1766559855876,
     "user": {
      "displayName": "teeradaj racharak",
      "userId": "17075908059307261120"
     },
     "user_tz": -540
    },
    "id": "YvWCpswBgfiU",
    "outputId": "801d27fd-de03-46e5-b1c1-469f50061118"
   },
   "outputs": [],
   "source": [
    "# @title 4. Start Processing\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_RUNS = 3\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "input_path = os.path.join(INPUT_DIR, TARGET_FILE_NAME)\n",
    "\n",
    "clean_filename = TARGET_FILE_NAME.replace('.csv', '')\n",
    "target_output_filename = f\"{OUTPUT_FILENAME_PREFIX}{clean_filename}_{timestamp}.csv\"\n",
    "output_path = os.path.join(OUTPUT_DIR, target_output_filename)\n",
    "\n",
    "print(f\"üöÄ Processing: {TARGET_FILE_NAME}\")\n",
    "print(f\"üîÑ Mode: 3 Runs (No Vote)\")\n",
    "print(f\"üìÇ Reading from: {input_path}\")\n",
    "print(f\"üíæ Saving to (New File): {output_path}\")\n",
    "\n",
    "if not os.path.exists(input_path):\n",
    "    print(f\"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå '{input_path}'\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(input_path)\n",
    "\n",
    "        if INPUT_COLUMN not in df.columns:\n",
    "            print(f\"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏∑‡πà‡∏≠ '{INPUT_COLUMN}' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV\")\n",
    "        else:\n",
    "            all_predictions = {f\"Prediction{i}\": [] for i in range(1, NUM_RUNS + 1)}\n",
    "\n",
    "            # --- 1. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏ô‡∏•‡∏π‡∏õ ---\n",
    "            for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Generating\"):\n",
    "                sentence = str(row[INPUT_COLUMN])\n",
    "                prompt_messages = create_prompt(sentence)\n",
    "\n",
    "                # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏¢‡πà‡∏≠‡∏¢ 3 ‡∏£‡∏≠‡∏ö\n",
    "                for i in range(1, NUM_RUNS + 1):\n",
    "                    raw_res = query_ollama(TARGET_MODEL, prompt_messages)\n",
    "                    final_pred = clean_gemma_response(raw_res) # ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô clean ‡∏Ç‡∏≠‡∏á gemma\n",
    "                    all_predictions[f\"Prediction{i}\"].append(final_pred)\n",
    "\n",
    "            ref_col_name = 'Expected_answer'\n",
    "\n",
    "            if ref_col_name in df.columns:\n",
    "                insert_loc_start = df.columns.get_loc(ref_col_name) + 1\n",
    "            else:\n",
    "                insert_loc_start = len(df.columns)\n",
    "\n",
    "            for i in range(1, NUM_RUNS + 1):\n",
    "                col_name = f\"Prediction{i}\"\n",
    "\n",
    "                if col_name in df.columns:\n",
    "                    df.drop(columns=[col_name], inplace=True)\n",
    "\n",
    "                current_loc = insert_loc_start + (i - 1)\n",
    "\n",
    "                if current_loc > len(df.columns):\n",
    "                    df[col_name] = all_predictions[col_name]\n",
    "                else:\n",
    "                    df.insert(current_loc, col_name, all_predictions[col_name])\n",
    "\n",
    "            # --- 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå ---\n",
    "            os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"\\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡πÑ‡∏ü‡∏•‡πå (3 Predictions) ‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Critical Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOvyGpNjGs4L4M3WwDiIGPm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
