{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2497,
     "status": "ok",
     "timestamp": 1766550848741,
     "user": {
      "displayName": "teeradaj racharak",
      "userId": "17075908059307261120"
     },
     "user_tz": -540
    },
    "id": "lGa2obiHDuzd",
    "outputId": "7987cfca-d68d-4910-c3f1-d1353d9a8dac"
   },
   "outputs": [],
   "source": [
    "# @title 0. Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 74165,
     "status": "ok",
     "timestamp": 1766551704152,
     "user": {
      "displayName": "teeradaj racharak",
      "userId": "17075908059307261120"
     },
     "user_tz": -540
    },
    "id": "cSgaWwsLEHQ4",
    "outputId": "1d3dc579-37d4-47f3-d1c9-6a5f7c53b73f"
   },
   "outputs": [],
   "source": [
    "# @title 1. Setup Environment & Install\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "!pip install pandas tqdm\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"Starting Ollama Server...\")\n",
    "process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "time.sleep(5)\n",
    "\n",
    "MODEL_NAME = \"qwen2.5:3b\"\n",
    "print(f\"Downloading model: {MODEL_NAME}...\")\n",
    "!ollama pull {MODEL_NAME}\n",
    "\n",
    "print(f\"‚úÖ Setup Complete! Model {MODEL_NAME} is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1766553302625,
     "user": {
      "displayName": "teeradaj racharak",
      "userId": "17075908059307261120"
     },
     "user_tz": -540
    },
    "id": "EqnY0XlyE2_u",
    "outputId": "d5baf7c1-89ac-4625-d421-d4606dc66b98"
   },
   "outputs": [],
   "source": [
    "# @title 2. Configuration\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "TARGET_FILE_NAME = \"sentiment_temporal.csv\"\n",
    "\n",
    "INPUT_DIR = \"/content/drive/MyDrive/ReaLearn/FY 2025/Interns - NU, Batch 3/AJCC_2026/Chanidapha/Dataset\"\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/ReaLearn/FY 2025/Interns - NU, Batch 3/AJCC_2026/Chanidapha/Result/qwen2.5:3b_temp1_Topp0.07/sentiment_temporal\"\n",
    "INPUT_COLUMN = \"Perturbed\"\n",
    "TARGET_MODEL = \"qwen2.5:3b\"\n",
    "OUTPUT_FILENAME_PREFIX = \"Result_qwen2.5:3b_temp1_\"\n",
    "\n",
    "print(f\"‚úÖ Config Saved: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå {TARGET_FILE_NAME} ‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• {TARGET_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1766551757904,
     "user": {
      "displayName": "teeradaj racharak",
      "userId": "17075908059307261120"
     },
     "user_tz": -540
    },
    "id": "-D_de4l4Firv",
    "outputId": "09290c5a-81e4-45be-f5cc-b3a72c12a688"
   },
   "outputs": [],
   "source": [
    "# @title 3. Helper Functions\n",
    "import re\n",
    "import requests\n",
    "\n",
    "def clean_qwen_response(text):\n",
    "    if not text: return \"Error\"\n",
    "\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    if \"positive\" in text_lower: return \"Positive\"\n",
    "    elif \"negative\" in text_lower: return \"Negative\"\n",
    "    elif \"neutral\" in text_lower: return \"Neutral\"\n",
    "    else: return text.strip()\n",
    "\n",
    "def create_prompt(sentence):\n",
    "    system_part = \"\"\"You are an assistant that classifies the sentiment of the\n",
    "message into positive, negative, and neutral. Given below is an example\n",
    "of the sentiment analysis task.\n",
    "\n",
    "Sentence: I had a bad experience\n",
    "Sentiment: Negative\"\"\"\n",
    "\n",
    "    user_part = f\"\"\"What is the sentiment of the following sentence? Limit your\n",
    "answer to only one of these options: Positive, Negative, or Neutral.\n",
    "{sentence}\"\"\"\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_part},\n",
    "        {\"role\": \"user\", \"content\": user_part}\n",
    "    ]\n",
    "\n",
    "def query_ollama(model, messages):\n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model, \"messages\": messages, \"stream\": False,\n",
    "        \"options\": {\"temperature\": 1.0,\n",
    "                    \"top_p\":0.07}\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()['message']['content']\n",
    "        else:\n",
    "            return f\"Error: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "print(\"‚úÖ Functions for Qwen Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bgq8zCAFFj8_",
    "outputId": "0cdbde44-fb32-4279-a3e5-40c7bfe0ff3a"
   },
   "outputs": [],
   "source": [
    "# @title 4. Start Processing\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_RUNS = 3\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "input_path = os.path.join(INPUT_DIR, TARGET_FILE_NAME)\n",
    "clean_filename = TARGET_FILE_NAME.replace('.csv', '')\n",
    "target_output_filename = f\"{OUTPUT_FILENAME_PREFIX}{clean_filename}_{timestamp}.csv\"\n",
    "output_path = os.path.join(OUTPUT_DIR, target_output_filename)\n",
    "\n",
    "print(f\"üöÄ Processing with {TARGET_MODEL}\")\n",
    "print(f\"üìÇ Reading: {input_path}\")\n",
    "print(f\"üíæ Saving to: {output_path}\")\n",
    "\n",
    "if not os.path.exists(input_path):\n",
    "    print(f\"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå '{input_path}'\")\n",
    "else:\n",
    "    try:\n",
    "        df = pd.read_csv(input_path)\n",
    "\n",
    "        if INPUT_COLUMN not in df.columns:\n",
    "            print(f\"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå '{INPUT_COLUMN}'\")\n",
    "        else:\n",
    "            all_predictions = {f\"Prediction{i}\": [] for i in range(1, NUM_RUNS + 1)}\n",
    "\n",
    "            for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Generating\"):\n",
    "                sentence = str(row[INPUT_COLUMN])\n",
    "                prompt_messages = create_prompt(sentence)\n",
    "\n",
    "                for i in range(1, NUM_RUNS + 1):\n",
    "                    raw_res = query_ollama(TARGET_MODEL, prompt_messages)\n",
    "\n",
    "                    final_pred = clean_qwen_response(raw_res)\n",
    "\n",
    "                    all_predictions[f\"Prediction{i}\"].append(final_pred)\n",
    "\n",
    "            ref_col_name = 'Expected_answer'\n",
    "            if ref_col_name in df.columns:\n",
    "                insert_loc_start = df.columns.get_loc(ref_col_name) + 1\n",
    "            else:\n",
    "                insert_loc_start = len(df.columns)\n",
    "\n",
    "            for i in range(1, NUM_RUNS + 1):\n",
    "                col_name = f\"Prediction{i}\"\n",
    "                if col_name in df.columns: df.drop(columns=[col_name], inplace=True)\n",
    "\n",
    "                current_loc = insert_loc_start + (i - 1)\n",
    "                if current_loc > len(df.columns):\n",
    "                    df[col_name] = all_predictions[col_name]\n",
    "                else:\n",
    "                    df.insert(current_loc, col_name, all_predictions[col_name])\n",
    "\n",
    "            os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"\\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå! ‡πÑ‡∏ü‡∏•‡πå Qwen ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Critical Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO7rPcEp6q5T683eCy4d5Ef",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
